{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKXI93R9JlgM"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTFUjkvQJlgO"
      },
      "source": [
        "# 各パス指定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIbkw6dUJlgQ"
      },
      "outputs": [],
      "source": [
        "dataset = '/content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history.csv'\n",
        "model_save_path = '/content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EvbHLKZJlgR"
      },
      "source": [
        "# 分類数設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGsqneFGJlgR"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NPxhCUgJlgS"
      },
      "source": [
        "# 入力長"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Wu-tsCYJlgS"
      },
      "outputs": [],
      "source": [
        "TIME_STEPS = 16\n",
        "DIMENSION = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBs67dW9JlgS"
      },
      "source": [
        "# 学習データ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61W6Hli5WtPy",
        "outputId": "ac6e2ff7-73c3-4e87-aa06-cc5cc05dea24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3WI3aOdJlgT"
      },
      "outputs": [],
      "source": [
        "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (TIME_STEPS * DIMENSION) + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJsIZVGcJlgT"
      },
      "outputs": [],
      "source": [
        "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AWg87D9JlgU"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miIhw2mnJlgU"
      },
      "source": [
        "# モデル構築"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P1zNtAoJlgU"
      },
      "outputs": [],
      "source": [
        "use_lstm = False\n",
        "model = None\n",
        "\n",
        "if use_lstm:\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
        "        tf.keras.layers.Reshape((TIME_STEPS, DIMENSION), input_shape=(TIME_STEPS * DIMENSION, )), \n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.LSTM(16, input_shape=[TIME_STEPS, DIMENSION]),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(10, activation='relu'),\n",
        "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "else:\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(24, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(10, activation='relu'),\n",
        "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyQjoXKMJlgV",
        "outputId": "1a7ca0f5-145f-45a3-d052-0cc92c912146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 24)                792       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 24)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                250       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,064\n",
            "Trainable params: 1,064\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAhrmqV2JlgX"
      },
      "outputs": [],
      "source": [
        "# モデルチェックポイントのコールバック\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False)\n",
        "# 早期打ち切り用コールバック\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ecXNDjMJlgX"
      },
      "outputs": [],
      "source": [
        "# モデルコンパイル\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO4dcW2KJlgY"
      },
      "source": [
        "# モデル訓練"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05DIL87zJlgY",
        "outputId": "04c4830c-7d1e-4122-dc5e-62cd25f4c1cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            " 1/15 [=>............................] - ETA: 9s - loss: 0.6939 - accuracy: 0.4922\n",
            "Epoch 1: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 0.6883 - accuracy: 0.5016 - val_loss: 0.6841 - val_accuracy: 0.5866\n",
            "Epoch 2/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.6793 - accuracy: 0.5469\n",
            "Epoch 2: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6840 - accuracy: 0.5579 - val_loss: 0.6787 - val_accuracy: 0.7488\n",
            "Epoch 3/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.6755 - accuracy: 0.6328\n",
            "Epoch 3: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6784 - accuracy: 0.6162 - val_loss: 0.6721 - val_accuracy: 0.7568\n",
            "Epoch 4/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.6713 - accuracy: 0.6250\n",
            "Epoch 4: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6724 - accuracy: 0.6561 - val_loss: 0.6645 - val_accuracy: 0.8188\n",
            "Epoch 5/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.6510 - accuracy: 0.7266\n",
            "Epoch 5: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6635 - accuracy: 0.6943 - val_loss: 0.6548 - val_accuracy: 0.8315\n",
            "Epoch 6/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.6683 - accuracy: 0.6406\n",
            "Epoch 6: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6530 - accuracy: 0.7166 - val_loss: 0.6428 - val_accuracy: 0.8601\n",
            "Epoch 7/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.6517 - accuracy: 0.7422\n",
            "Epoch 7: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6412 - accuracy: 0.7373 - val_loss: 0.6285 - val_accuracy: 0.8792\n",
            "Epoch 8/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.6499 - accuracy: 0.7500\n",
            "Epoch 8: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6234 - accuracy: 0.7781 - val_loss: 0.6107 - val_accuracy: 0.8951\n",
            "Epoch 9/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.6345 - accuracy: 0.7812\n",
            "Epoch 9: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6111 - accuracy: 0.7808 - val_loss: 0.5901 - val_accuracy: 0.9173\n",
            "Epoch 10/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.5839 - accuracy: 0.8203\n",
            "Epoch 10: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5844 - accuracy: 0.8100 - val_loss: 0.5653 - val_accuracy: 0.9380\n",
            "Epoch 11/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.5672 - accuracy: 0.8203\n",
            "Epoch 11: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5673 - accuracy: 0.8169 - val_loss: 0.5390 - val_accuracy: 0.9491\n",
            "Epoch 12/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.5450 - accuracy: 0.8125\n",
            "Epoch 12: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5347 - accuracy: 0.8211 - val_loss: 0.5087 - val_accuracy: 0.9587\n",
            "Epoch 13/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.5144 - accuracy: 0.8672\n",
            "Epoch 13: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5102 - accuracy: 0.8392 - val_loss: 0.4770 - val_accuracy: 0.9587\n",
            "Epoch 14/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.4834 - accuracy: 0.9062\n",
            "Epoch 14: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.8721 - val_loss: 0.4461 - val_accuracy: 0.9618\n",
            "Epoch 15/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.4313 - accuracy: 0.8828\n",
            "Epoch 15: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4622 - accuracy: 0.8493 - val_loss: 0.4189 - val_accuracy: 0.9618\n",
            "Epoch 16/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.4389 - accuracy: 0.8906\n",
            "Epoch 16: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.8631 - val_loss: 0.3903 - val_accuracy: 0.9666\n",
            "Epoch 17/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.3971 - accuracy: 0.8984\n",
            "Epoch 17: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8609 - val_loss: 0.3647 - val_accuracy: 0.9650\n",
            "Epoch 18/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.4097 - accuracy: 0.8438\n",
            "Epoch 18: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8753 - val_loss: 0.3445 - val_accuracy: 0.9666\n",
            "Epoch 19/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.4592 - accuracy: 0.8672\n",
            "Epoch 19: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.8811 - val_loss: 0.3268 - val_accuracy: 0.9682\n",
            "Epoch 20/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.3549 - accuracy: 0.9141\n",
            "Epoch 20: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8859 - val_loss: 0.3088 - val_accuracy: 0.9682\n",
            "Epoch 21/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.3856 - accuracy: 0.8516\n",
            "Epoch 21: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3496 - accuracy: 0.8875 - val_loss: 0.2925 - val_accuracy: 0.9682\n",
            "Epoch 22/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.3168 - accuracy: 0.9141\n",
            "Epoch 22: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3259 - accuracy: 0.8869 - val_loss: 0.2754 - val_accuracy: 0.9634\n",
            "Epoch 23/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2741 - accuracy: 0.8984\n",
            "Epoch 23: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3109 - accuracy: 0.9034 - val_loss: 0.2632 - val_accuracy: 0.9714\n",
            "Epoch 24/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2358 - accuracy: 0.9531\n",
            "Epoch 24: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3010 - accuracy: 0.9034 - val_loss: 0.2526 - val_accuracy: 0.9714\n",
            "Epoch 25/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2483 - accuracy: 0.9297\n",
            "Epoch 25: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2886 - accuracy: 0.9066 - val_loss: 0.2404 - val_accuracy: 0.9714\n",
            "Epoch 26/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2357 - accuracy: 0.8906\n",
            "Epoch 26: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2843 - accuracy: 0.9140 - val_loss: 0.2323 - val_accuracy: 0.9714\n",
            "Epoch 27/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2504 - accuracy: 0.9062\n",
            "Epoch 27: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2888 - accuracy: 0.9050 - val_loss: 0.2268 - val_accuracy: 0.9730\n",
            "Epoch 28/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2978 - accuracy: 0.8906\n",
            "Epoch 28: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3044 - accuracy: 0.9029 - val_loss: 0.2246 - val_accuracy: 0.9730\n",
            "Epoch 29/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2621 - accuracy: 0.8984\n",
            "Epoch 29: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2775 - accuracy: 0.9034 - val_loss: 0.2158 - val_accuracy: 0.9714\n",
            "Epoch 30/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2376 - accuracy: 0.9141\n",
            "Epoch 30: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2680 - accuracy: 0.9082 - val_loss: 0.2110 - val_accuracy: 0.9730\n",
            "Epoch 31/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2435 - accuracy: 0.9062\n",
            "Epoch 31: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2617 - accuracy: 0.9257 - val_loss: 0.2056 - val_accuracy: 0.9730\n",
            "Epoch 32/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.3537 - accuracy: 0.8516\n",
            "Epoch 32: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2603 - accuracy: 0.9098 - val_loss: 0.1998 - val_accuracy: 0.9714\n",
            "Epoch 33/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2268 - accuracy: 0.9297\n",
            "Epoch 33: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2567 - accuracy: 0.9140 - val_loss: 0.1959 - val_accuracy: 0.9730\n",
            "Epoch 34/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1977 - accuracy: 0.9453\n",
            "Epoch 34: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2440 - accuracy: 0.9156 - val_loss: 0.1947 - val_accuracy: 0.9730\n",
            "Epoch 35/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1963 - accuracy: 0.9453\n",
            "Epoch 35: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2542 - accuracy: 0.9246 - val_loss: 0.1883 - val_accuracy: 0.9730\n",
            "Epoch 36/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2262 - accuracy: 0.9141\n",
            "Epoch 36: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2430 - accuracy: 0.9193 - val_loss: 0.1816 - val_accuracy: 0.9730\n",
            "Epoch 37/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2472 - accuracy: 0.8906\n",
            "Epoch 37: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2263 - accuracy: 0.9220 - val_loss: 0.1793 - val_accuracy: 0.9730\n",
            "Epoch 38/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2081 - accuracy: 0.9297\n",
            "Epoch 38: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2135 - accuracy: 0.9299 - val_loss: 0.1740 - val_accuracy: 0.9730\n",
            "Epoch 39/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1975 - accuracy: 0.9297\n",
            "Epoch 39: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2137 - accuracy: 0.9342 - val_loss: 0.1699 - val_accuracy: 0.9714\n",
            "Epoch 40/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1907 - accuracy: 0.9531\n",
            "Epoch 40: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2295 - accuracy: 0.9278 - val_loss: 0.1695 - val_accuracy: 0.9746\n",
            "Epoch 41/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1972 - accuracy: 0.9297\n",
            "Epoch 41: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2225 - accuracy: 0.9230 - val_loss: 0.1674 - val_accuracy: 0.9746\n",
            "Epoch 42/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.3393 - accuracy: 0.8984\n",
            "Epoch 42: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2203 - accuracy: 0.9241 - val_loss: 0.1681 - val_accuracy: 0.9746\n",
            "Epoch 43/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1898 - accuracy: 0.9375\n",
            "Epoch 43: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2278 - accuracy: 0.9225 - val_loss: 0.1668 - val_accuracy: 0.9746\n",
            "Epoch 44/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1909 - accuracy: 0.9297\n",
            "Epoch 44: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2106 - accuracy: 0.9315 - val_loss: 0.1614 - val_accuracy: 0.9762\n",
            "Epoch 45/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1638 - accuracy: 0.9531\n",
            "Epoch 45: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2164 - accuracy: 0.9252 - val_loss: 0.1589 - val_accuracy: 0.9762\n",
            "Epoch 46/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2155 - accuracy: 0.9219\n",
            "Epoch 46: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2181 - accuracy: 0.9294 - val_loss: 0.1577 - val_accuracy: 0.9762\n",
            "Epoch 47/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1977 - accuracy: 0.9297\n",
            "Epoch 47: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2001 - accuracy: 0.9268 - val_loss: 0.1570 - val_accuracy: 0.9762\n",
            "Epoch 48/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2130 - accuracy: 0.8984\n",
            "Epoch 48: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2054 - accuracy: 0.9294 - val_loss: 0.1559 - val_accuracy: 0.9746\n",
            "Epoch 49/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1629 - accuracy: 0.9453\n",
            "Epoch 49: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1954 - accuracy: 0.9363 - val_loss: 0.1560 - val_accuracy: 0.9746\n",
            "Epoch 50/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1569 - accuracy: 0.9375\n",
            "Epoch 50: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1925 - accuracy: 0.9395 - val_loss: 0.1551 - val_accuracy: 0.9730\n",
            "Epoch 51/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1729 - accuracy: 0.9375\n",
            "Epoch 51: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1824 - accuracy: 0.9379 - val_loss: 0.1498 - val_accuracy: 0.9762\n",
            "Epoch 52/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2202 - accuracy: 0.9141\n",
            "Epoch 52: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2018 - accuracy: 0.9352 - val_loss: 0.1471 - val_accuracy: 0.9762\n",
            "Epoch 53/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1491 - accuracy: 0.9531\n",
            "Epoch 53: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1752 - accuracy: 0.9374 - val_loss: 0.1473 - val_accuracy: 0.9762\n",
            "Epoch 54/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2093 - accuracy: 0.8984\n",
            "Epoch 54: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1938 - accuracy: 0.9273 - val_loss: 0.1454 - val_accuracy: 0.9762\n",
            "Epoch 55/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1826 - accuracy: 0.9453\n",
            "Epoch 55: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1897 - accuracy: 0.9400 - val_loss: 0.1456 - val_accuracy: 0.9762\n",
            "Epoch 56/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1860 - accuracy: 0.9531\n",
            "Epoch 56: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1767 - accuracy: 0.9411 - val_loss: 0.1465 - val_accuracy: 0.9762\n",
            "Epoch 57/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1287 - accuracy: 0.9609\n",
            "Epoch 57: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2038 - accuracy: 0.9315 - val_loss: 0.1446 - val_accuracy: 0.9746\n",
            "Epoch 58/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1958 - accuracy: 0.9297\n",
            "Epoch 58: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1880 - accuracy: 0.9347 - val_loss: 0.1458 - val_accuracy: 0.9746\n",
            "Epoch 59/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1709 - accuracy: 0.9375\n",
            "Epoch 59: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1811 - accuracy: 0.9406 - val_loss: 0.1455 - val_accuracy: 0.9746\n",
            "Epoch 60/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1960 - accuracy: 0.9219\n",
            "Epoch 60: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1783 - accuracy: 0.9400 - val_loss: 0.1433 - val_accuracy: 0.9746\n",
            "Epoch 61/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1358 - accuracy: 0.9766\n",
            "Epoch 61: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1749 - accuracy: 0.9326 - val_loss: 0.1416 - val_accuracy: 0.9762\n",
            "Epoch 62/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1625 - accuracy: 0.9531\n",
            "Epoch 62: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2004 - accuracy: 0.9390 - val_loss: 0.1419 - val_accuracy: 0.9777\n",
            "Epoch 63/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1884 - accuracy: 0.9531\n",
            "Epoch 63: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1694 - accuracy: 0.9432 - val_loss: 0.1419 - val_accuracy: 0.9777\n",
            "Epoch 64/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1889 - accuracy: 0.9141\n",
            "Epoch 64: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2109 - accuracy: 0.9294 - val_loss: 0.1416 - val_accuracy: 0.9777\n",
            "Epoch 65/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1418 - accuracy: 0.9688\n",
            "Epoch 65: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1810 - accuracy: 0.9549 - val_loss: 0.1443 - val_accuracy: 0.9762\n",
            "Epoch 66/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1488 - accuracy: 0.9688\n",
            "Epoch 66: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1745 - accuracy: 0.9400 - val_loss: 0.1436 - val_accuracy: 0.9762\n",
            "Epoch 67/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2234 - accuracy: 0.9062\n",
            "Epoch 67: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1768 - accuracy: 0.9337 - val_loss: 0.1419 - val_accuracy: 0.9777\n",
            "Epoch 68/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1891 - accuracy: 0.9297\n",
            "Epoch 68: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1788 - accuracy: 0.9326 - val_loss: 0.1427 - val_accuracy: 0.9777\n",
            "Epoch 69/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1566 - accuracy: 0.9609\n",
            "Epoch 69: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1917 - accuracy: 0.9411 - val_loss: 0.1397 - val_accuracy: 0.9777\n",
            "Epoch 70/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1415 - accuracy: 0.9531\n",
            "Epoch 70: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1698 - accuracy: 0.9363 - val_loss: 0.1437 - val_accuracy: 0.9777\n",
            "Epoch 71/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1665 - accuracy: 0.9219\n",
            "Epoch 71: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1720 - accuracy: 0.9400 - val_loss: 0.1465 - val_accuracy: 0.9793\n",
            "Epoch 72/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2543 - accuracy: 0.9375\n",
            "Epoch 72: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1829 - accuracy: 0.9395 - val_loss: 0.1441 - val_accuracy: 0.9777\n",
            "Epoch 73/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1401 - accuracy: 0.9609\n",
            "Epoch 73: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1874 - accuracy: 0.9400 - val_loss: 0.1401 - val_accuracy: 0.9777\n",
            "Epoch 74/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1938 - accuracy: 0.9297\n",
            "Epoch 74: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1787 - accuracy: 0.9400 - val_loss: 0.1394 - val_accuracy: 0.9777\n",
            "Epoch 75/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2314 - accuracy: 0.8750\n",
            "Epoch 75: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1760 - accuracy: 0.9400 - val_loss: 0.1385 - val_accuracy: 0.9777\n",
            "Epoch 76/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1366 - accuracy: 0.9297\n",
            "Epoch 76: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1788 - accuracy: 0.9416 - val_loss: 0.1397 - val_accuracy: 0.9777\n",
            "Epoch 77/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.3462 - accuracy: 0.9297\n",
            "Epoch 77: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1749 - accuracy: 0.9464 - val_loss: 0.1389 - val_accuracy: 0.9777\n",
            "Epoch 78/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1371 - accuracy: 0.9609\n",
            "Epoch 78: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1568 - accuracy: 0.9432 - val_loss: 0.1377 - val_accuracy: 0.9777\n",
            "Epoch 79/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1178 - accuracy: 0.9688\n",
            "Epoch 79: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1665 - accuracy: 0.9395 - val_loss: 0.1379 - val_accuracy: 0.9777\n",
            "Epoch 80/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1393 - accuracy: 0.9375\n",
            "Epoch 80: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1513 - accuracy: 0.9459 - val_loss: 0.1399 - val_accuracy: 0.9777\n",
            "Epoch 81/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1604 - accuracy: 0.9688\n",
            "Epoch 81: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1627 - accuracy: 0.9437 - val_loss: 0.1410 - val_accuracy: 0.9777\n",
            "Epoch 82/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1451 - accuracy: 0.9609\n",
            "Epoch 82: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1685 - accuracy: 0.9443 - val_loss: 0.1393 - val_accuracy: 0.9777\n",
            "Epoch 83/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1323 - accuracy: 0.9531\n",
            "Epoch 83: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1612 - accuracy: 0.9416 - val_loss: 0.1399 - val_accuracy: 0.9777\n",
            "Epoch 84/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1071 - accuracy: 0.9766\n",
            "Epoch 84: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1606 - accuracy: 0.9448 - val_loss: 0.1373 - val_accuracy: 0.9777\n",
            "Epoch 85/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1705 - accuracy: 0.9375\n",
            "Epoch 85: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1704 - accuracy: 0.9406 - val_loss: 0.1343 - val_accuracy: 0.9777\n",
            "Epoch 86/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1506 - accuracy: 0.9531\n",
            "Epoch 86: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1510 - accuracy: 0.9501 - val_loss: 0.1357 - val_accuracy: 0.9777\n",
            "Epoch 87/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1649 - accuracy: 0.9219\n",
            "Epoch 87: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1700 - accuracy: 0.9411 - val_loss: 0.1354 - val_accuracy: 0.9777\n",
            "Epoch 88/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1932 - accuracy: 0.9453\n",
            "Epoch 88: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1324 - accuracy: 0.9565 - val_loss: 0.1348 - val_accuracy: 0.9777\n",
            "Epoch 89/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1696 - accuracy: 0.9297\n",
            "Epoch 89: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1641 - accuracy: 0.9384 - val_loss: 0.1344 - val_accuracy: 0.9777\n",
            "Epoch 90/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0938 - accuracy: 0.9688\n",
            "Epoch 90: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1578 - accuracy: 0.9427 - val_loss: 0.1348 - val_accuracy: 0.9777\n",
            "Epoch 91/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2507 - accuracy: 0.9062\n",
            "Epoch 91: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1736 - accuracy: 0.9406 - val_loss: 0.1342 - val_accuracy: 0.9777\n",
            "Epoch 92/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1745 - accuracy: 0.9453\n",
            "Epoch 92: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1503 - accuracy: 0.9448 - val_loss: 0.1363 - val_accuracy: 0.9777\n",
            "Epoch 93/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1822 - accuracy: 0.9453\n",
            "Epoch 93: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1949 - accuracy: 0.9437 - val_loss: 0.1363 - val_accuracy: 0.9777\n",
            "Epoch 94/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1843 - accuracy: 0.9219\n",
            "Epoch 94: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1625 - accuracy: 0.9443 - val_loss: 0.1352 - val_accuracy: 0.9777\n",
            "Epoch 95/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1464 - accuracy: 0.9453\n",
            "Epoch 95: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1819 - accuracy: 0.9421 - val_loss: 0.1357 - val_accuracy: 0.9777\n",
            "Epoch 96/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1077 - accuracy: 0.9688\n",
            "Epoch 96: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1488 - accuracy: 0.9475 - val_loss: 0.1309 - val_accuracy: 0.9777\n",
            "Epoch 97/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1656 - accuracy: 0.9375\n",
            "Epoch 97: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1790 - accuracy: 0.9342 - val_loss: 0.1294 - val_accuracy: 0.9777\n",
            "Epoch 98/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1239 - accuracy: 0.9609\n",
            "Epoch 98: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1764 - accuracy: 0.9469 - val_loss: 0.1275 - val_accuracy: 0.9777\n",
            "Epoch 99/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1291 - accuracy: 0.9609\n",
            "Epoch 99: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1458 - accuracy: 0.9512 - val_loss: 0.1282 - val_accuracy: 0.9777\n",
            "Epoch 100/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1787 - accuracy: 0.9219\n",
            "Epoch 100: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1502 - accuracy: 0.9480 - val_loss: 0.1296 - val_accuracy: 0.9777\n",
            "Epoch 101/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1899 - accuracy: 0.9141\n",
            "Epoch 101: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1405 - accuracy: 0.9485 - val_loss: 0.1301 - val_accuracy: 0.9777\n",
            "Epoch 102/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1807 - accuracy: 0.9219\n",
            "Epoch 102: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1329 - accuracy: 0.9538 - val_loss: 0.1293 - val_accuracy: 0.9777\n",
            "Epoch 103/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1396 - accuracy: 0.9297\n",
            "Epoch 103: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1493 - accuracy: 0.9475 - val_loss: 0.1304 - val_accuracy: 0.9777\n",
            "Epoch 104/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1836 - accuracy: 0.9453\n",
            "Epoch 104: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1633 - accuracy: 0.9421 - val_loss: 0.1314 - val_accuracy: 0.9793\n",
            "Epoch 105/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.4725 - accuracy: 0.9609\n",
            "Epoch 105: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1819 - accuracy: 0.9437 - val_loss: 0.1324 - val_accuracy: 0.9793\n",
            "Epoch 106/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1230 - accuracy: 0.9688\n",
            "Epoch 106: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1417 - accuracy: 0.9522 - val_loss: 0.1329 - val_accuracy: 0.9793\n",
            "Epoch 107/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1708 - accuracy: 0.9141\n",
            "Epoch 107: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1449 - accuracy: 0.9490 - val_loss: 0.1303 - val_accuracy: 0.9777\n",
            "Epoch 108/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1919 - accuracy: 0.9062\n",
            "Epoch 108: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1728 - accuracy: 0.9384 - val_loss: 0.1299 - val_accuracy: 0.9777\n",
            "Epoch 109/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1399 - accuracy: 0.9609\n",
            "Epoch 109: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1429 - accuracy: 0.9544 - val_loss: 0.1305 - val_accuracy: 0.9777\n",
            "Epoch 110/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1050 - accuracy: 0.9688\n",
            "Epoch 110: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1549 - accuracy: 0.9432 - val_loss: 0.1313 - val_accuracy: 0.9777\n",
            "Epoch 111/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2076 - accuracy: 0.9062\n",
            "Epoch 111: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1690 - accuracy: 0.9352 - val_loss: 0.1297 - val_accuracy: 0.9777\n",
            "Epoch 112/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.3204 - accuracy: 0.8672\n",
            "Epoch 112: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1662 - accuracy: 0.9421 - val_loss: 0.1302 - val_accuracy: 0.9777\n",
            "Epoch 113/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1398 - accuracy: 0.9609\n",
            "Epoch 113: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1294 - accuracy: 0.9549 - val_loss: 0.1266 - val_accuracy: 0.9777\n",
            "Epoch 114/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1306 - accuracy: 0.9531\n",
            "Epoch 114: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1792 - accuracy: 0.9469 - val_loss: 0.1251 - val_accuracy: 0.9777\n",
            "Epoch 115/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1279 - accuracy: 0.9453\n",
            "Epoch 115: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1598 - accuracy: 0.9475 - val_loss: 0.1265 - val_accuracy: 0.9777\n",
            "Epoch 116/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.5075 - accuracy: 0.9453\n",
            "Epoch 116: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1660 - accuracy: 0.9528 - val_loss: 0.1274 - val_accuracy: 0.9777\n",
            "Epoch 117/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1148 - accuracy: 0.9531\n",
            "Epoch 117: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1491 - accuracy: 0.9485 - val_loss: 0.1268 - val_accuracy: 0.9777\n",
            "Epoch 118/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0988 - accuracy: 0.9531\n",
            "Epoch 118: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1471 - accuracy: 0.9485 - val_loss: 0.1278 - val_accuracy: 0.9777\n",
            "Epoch 119/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1489 - accuracy: 0.9453\n",
            "Epoch 119: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1324 - accuracy: 0.9517 - val_loss: 0.1279 - val_accuracy: 0.9777\n",
            "Epoch 120/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1371 - accuracy: 0.9531\n",
            "Epoch 120: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1694 - accuracy: 0.9400 - val_loss: 0.1255 - val_accuracy: 0.9777\n",
            "Epoch 121/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2909 - accuracy: 0.9453\n",
            "Epoch 121: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1747 - accuracy: 0.9453 - val_loss: 0.1229 - val_accuracy: 0.9777\n",
            "Epoch 122/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1132 - accuracy: 0.9531\n",
            "Epoch 122: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1421 - accuracy: 0.9522 - val_loss: 0.1246 - val_accuracy: 0.9777\n",
            "Epoch 123/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1401 - accuracy: 0.9375\n",
            "Epoch 123: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1424 - accuracy: 0.9512 - val_loss: 0.1255 - val_accuracy: 0.9777\n",
            "Epoch 124/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1150 - accuracy: 0.9688\n",
            "Epoch 124: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1576 - accuracy: 0.9390 - val_loss: 0.1256 - val_accuracy: 0.9777\n",
            "Epoch 125/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1434 - accuracy: 0.9531\n",
            "Epoch 125: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1554 - accuracy: 0.9475 - val_loss: 0.1236 - val_accuracy: 0.9777\n",
            "Epoch 126/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1659 - accuracy: 0.9531\n",
            "Epoch 126: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1427 - accuracy: 0.9538 - val_loss: 0.1241 - val_accuracy: 0.9793\n",
            "Epoch 127/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0948 - accuracy: 0.9609\n",
            "Epoch 127: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1540 - accuracy: 0.9411 - val_loss: 0.1276 - val_accuracy: 0.9793\n",
            "Epoch 128/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1657 - accuracy: 0.9609\n",
            "Epoch 128: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1423 - accuracy: 0.9533 - val_loss: 0.1272 - val_accuracy: 0.9793\n",
            "Epoch 129/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2263 - accuracy: 0.8828\n",
            "Epoch 129: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1897 - accuracy: 0.9374 - val_loss: 0.1241 - val_accuracy: 0.9777\n",
            "Epoch 130/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1680 - accuracy: 0.9375\n",
            "Epoch 130: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1346 - accuracy: 0.9512 - val_loss: 0.1230 - val_accuracy: 0.9777\n",
            "Epoch 131/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1017 - accuracy: 0.9609\n",
            "Epoch 131: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1527 - accuracy: 0.9432 - val_loss: 0.1227 - val_accuracy: 0.9777\n",
            "Epoch 132/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1356 - accuracy: 0.9453\n",
            "Epoch 132: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1253 - accuracy: 0.9581 - val_loss: 0.1202 - val_accuracy: 0.9777\n",
            "Epoch 133/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1870 - accuracy: 0.8984\n",
            "Epoch 133: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1663 - accuracy: 0.9400 - val_loss: 0.1151 - val_accuracy: 0.9777\n",
            "Epoch 134/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1720 - accuracy: 0.9141\n",
            "Epoch 134: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1417 - accuracy: 0.9490 - val_loss: 0.1154 - val_accuracy: 0.9777\n",
            "Epoch 135/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0862 - accuracy: 0.9609\n",
            "Epoch 135: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1406 - accuracy: 0.9528 - val_loss: 0.1185 - val_accuracy: 0.9793\n",
            "Epoch 136/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1719 - accuracy: 0.9375\n",
            "Epoch 136: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1285 - accuracy: 0.9533 - val_loss: 0.1209 - val_accuracy: 0.9777\n",
            "Epoch 137/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1556 - accuracy: 0.9375\n",
            "Epoch 137: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1317 - accuracy: 0.9597 - val_loss: 0.1208 - val_accuracy: 0.9793\n",
            "Epoch 138/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1218 - accuracy: 0.9688\n",
            "Epoch 138: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1444 - accuracy: 0.9512 - val_loss: 0.1203 - val_accuracy: 0.9793\n",
            "Epoch 139/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1257 - accuracy: 0.9609\n",
            "Epoch 139: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1892 - accuracy: 0.9459 - val_loss: 0.1179 - val_accuracy: 0.9777\n",
            "Epoch 140/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1467 - accuracy: 0.9375\n",
            "Epoch 140: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1432 - accuracy: 0.9485 - val_loss: 0.1178 - val_accuracy: 0.9762\n",
            "Epoch 141/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1416 - accuracy: 0.9766\n",
            "Epoch 141: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1389 - accuracy: 0.9528 - val_loss: 0.1204 - val_accuracy: 0.9777\n",
            "Epoch 142/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1091 - accuracy: 0.9688\n",
            "Epoch 142: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1611 - accuracy: 0.9475 - val_loss: 0.1193 - val_accuracy: 0.9777\n",
            "Epoch 143/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0812 - accuracy: 0.9766\n",
            "Epoch 143: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1283 - accuracy: 0.9544 - val_loss: 0.1189 - val_accuracy: 0.9793\n",
            "Epoch 144/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1125 - accuracy: 0.9609\n",
            "Epoch 144: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1262 - accuracy: 0.9549 - val_loss: 0.1198 - val_accuracy: 0.9793\n",
            "Epoch 145/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1520 - accuracy: 0.9531\n",
            "Epoch 145: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1488 - accuracy: 0.9517 - val_loss: 0.1194 - val_accuracy: 0.9793\n",
            "Epoch 146/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1381 - accuracy: 0.9531\n",
            "Epoch 146: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1630 - accuracy: 0.9480 - val_loss: 0.1174 - val_accuracy: 0.9777\n",
            "Epoch 147/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1387 - accuracy: 0.9453\n",
            "Epoch 147: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1483 - accuracy: 0.9448 - val_loss: 0.1197 - val_accuracy: 0.9793\n",
            "Epoch 148/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.2046 - accuracy: 0.8984\n",
            "Epoch 148: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1424 - accuracy: 0.9453 - val_loss: 0.1217 - val_accuracy: 0.9793\n",
            "Epoch 149/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1041 - accuracy: 0.9766\n",
            "Epoch 149: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1296 - accuracy: 0.9565 - val_loss: 0.1239 - val_accuracy: 0.9793\n",
            "Epoch 150/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1396 - accuracy: 0.9375\n",
            "Epoch 150: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1601 - accuracy: 0.9528 - val_loss: 0.1222 - val_accuracy: 0.9793\n",
            "Epoch 151/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1181 - accuracy: 0.9531\n",
            "Epoch 151: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1546 - accuracy: 0.9459 - val_loss: 0.1195 - val_accuracy: 0.9793\n",
            "Epoch 152/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0984 - accuracy: 0.9531\n",
            "Epoch 152: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1261 - accuracy: 0.9544 - val_loss: 0.1184 - val_accuracy: 0.9793\n",
            "Epoch 153/1000\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0760 - accuracy: 0.9844\n",
            "Epoch 153: saving model to /content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1275 - accuracy: 0.9538 - val_loss: 0.1168 - val_accuracy: 0.9777\n",
            "Epoch 153: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8453cab820>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[cp_callback, es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23y98yrGJlgZ"
      },
      "outputs": [],
      "source": [
        "# 保存したモデルのロード\n",
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ow2CC2vJlgZ",
        "outputId": "9ceee0b7-c8ba-46a0-b2a4-01c4201aa9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 77ms/step\n",
            "[0.99864656 0.00135342]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# 推論テスト\n",
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mUApTLQJlga"
      },
      "source": [
        "# 混同行列"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "lDYFmVxRJlga",
        "outputId": "6776129c-7363-42a7-eabb-562f5b054b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       307\n",
            "           1       0.98      0.97      0.98       322\n",
            "\n",
            "    accuracy                           0.98       629\n",
            "   macro avg       0.98      0.98      0.98       629\n",
            "weighted avg       0.98      0.98      0.98       629\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsAX7SzGJlgb"
      },
      "source": [
        "# Tensorflow-Lite用のモデルへ変換"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0ysr1bqJlgb",
        "outputId": "8b09b33b-710d-4fb3-ca11-0a71c09611c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "# 推論専用のモデルとして保存\n",
        "model.save(model_save_path, include_optimizer=False)\n",
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pdzu5BvWJlgb"
      },
      "outputs": [],
      "source": [
        "tflite_save_path = '/content/drive/MyDrive/hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.tflite'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1OW4VEqJlgb",
        "outputId": "addb71bc-0efe-4dfe-c6cd-d3ed8dcaac15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6288"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# モデルを変換(量子化\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)  # converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EC8ASV6Jlgc"
      },
      "source": [
        "# 推論テスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztkZsQMQJlgc"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKm77LclJlgc",
        "outputId": "6a395d11-0ef4-40db-eec3-b982e221f362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'serving_default_input_1:0', 'index': 0, 'shape': array([ 1, 32], dtype=int32), 'shape_signature': array([-1, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ],
      "source": [
        "# 入出力テンソルを取得\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(input_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nki9JctjJlgd"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REqKsz3-Jlgd",
        "outputId": "7eb851d2-b53c-4ad8-8c16-e2473539347d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.27 ms, sys: 0 ns, total: 1.27 ms\n",
            "Wall time: 3.24 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# 推論実施\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIHA0Xn6Jlgd",
        "outputId": "8c40a9f1-7f9f-4d48-d6ce-4bf36bb9e293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99864656 0.00135342]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}